{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config\n",
    "from config import UNetTraining\n",
    "# from config import UNetTraining\n",
    "config = UNetTraining.Configuration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import colors\n",
    "colors = colors.bcolors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "\n",
    "# import imgaug as ia\n",
    "# from imgaug import augmenters as iaa\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import imageio\n",
    "import os\n",
    "import time\n",
    "import rasterio.warp             # Reproject raster samples\n",
    "from functools import reduce\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from core.UNet import UNet\n",
    "from core.losses import tversky, accuracy, dice_coef, dice_loss, specificity, sensitivity\n",
    "from core.optimizers import adaDelta, adagrad, adam, nadam\n",
    "from core.frame_info import FrameInfo\n",
    "# from core.dataset_generator import DataGenerator\n",
    "from core.split_frames import split_dataset\n",
    "from core.visualize import display_images\n",
    "\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt  # plotting tools\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.patches import Polygon\n",
    "\n",
    "import warnings                  # ignore annoying warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import platform\n",
    "\n",
    "if platform == \"linux\" or platform == \"linux2\":\n",
    "    path_satellite = \"/home/jovyan/work/satellite_data/\"\n",
    "    path_labels = os.getcwd() + \"/1_labeled_data/tif/\"\n",
    "    cutouts_path = os.getcwd() + \"/2_cutouts/\"\n",
    "elif platform == \"darwin\":\n",
    "    path_data = \"/Users/leori/Desktop/BA/1_Data/\"\n",
    "    path_satellite = path_data + \"2_satellite/\"\n",
    "    path_labels = path_data + \"1_labeled_data/tif/\"\n",
    "    cutouts_path = None\n",
    "elif platform == \"win32\":\n",
    "    print(\"Something went wrong\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Label Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get polygon coordinates \n",
    "import json\n",
    "g = json.loads(labels_bounding_boxes.to_json())\n",
    "coords = []\n",
    "for polygon in range(len(g)):\n",
    "    coords.append(g['features'][polygon]['geometry']['coordinates'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'g' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-08fbd1977029>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcoord_labels_bounding_boxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mpolygon\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mwest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msouth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpolygon\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpolygon\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0meast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpolygon\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpolygon\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'g' is not defined"
     ]
    }
   ],
   "source": [
    "from rasterio.windows import from_bounds\n",
    "from rasterio.plot import show\n",
    "# visualize labels\n",
    "src_label = rasterio.open(config.filepath_label)\n",
    "labels = []\n",
    "coord_labels_bounding_boxes = []\n",
    "for polygon in range(len(g)):\n",
    "    west, south = coords[polygon][0][0], coords[polygon][0][1]\n",
    "    east, north = coords[polygon][2][0], coords[polygon][2][1]\n",
    "    coord_labels_bounding_boxes.append((west, south, east, north))\n",
    "    print(polygon, \":\", coord_labels_bounding_boxes[polygon])\n",
    "    labels.append(src_label.read(1, window = from_bounds(west, south, east, north, src_label.transform)))\n",
    "    show(labels[polygon])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29.995271839179495, -26.495656803219298, 30.001920300509017, -26.501297921923136)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<osgeo.gdal.Dataset; proxy of <Swig Object of type 'GDALDatasetShadow *' at 0x7f9e76851e70> >"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29.748165906702567, -26.248664051688667, 29.76650030217796, -26.263430007776233)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<osgeo.gdal.Dataset; proxy of <Swig Object of type 'GDALDatasetShadow *' at 0x7f9e76851120> >"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from osgeo import gdal\n",
    "\n",
    "label_file = gdal.Open(config.filepath_label)\n",
    "filepath_labeled_areas = []\n",
    "for polygon in range(len(g)):\n",
    "    # same coordinates as above\n",
    "    west, south = coords[polygon][0][0], coords[polygon][0][1]\n",
    "    east, north = coords[polygon][2][0], coords[polygon][2][1]\n",
    "    # gdal only needs the coordingates in a different order\n",
    "    coord_labels_bounding_boxes.append((west, south, east, north))\n",
    "\n",
    "    filepath_labeled_area = config.path_labeled_data_areas + \"label-area-\" + str(polygon) + \".tif\"\n",
    "    filepath_labeled_areas.append(filepath_labeled_area)\n",
    "    cropped_window = (west,north,east,south) # coord_labels_bounding_boxes[polygon]\n",
    "    # print(filepath_labeled_area)\n",
    "    print(cropped_window)\n",
    "    gdal.Translate(filepath_labeled_area, label_file, projWin = cropped_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close rasterio & gdal dataset\n",
    "src_label.close() \n",
    "del label_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patchify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Label Area Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_area_1 = rasterio.open(filepath_labeled_areas[0])\n",
    "label_area_2 = rasterio.open(filepath_labeled_areas[1])\n",
    "opened_label_areas = [label_area_1, label_area_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2802, 2377)"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7727, 6223)"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1095\n"
     ]
    }
   ],
   "source": [
    "total_patches = 0\n",
    "for x in [label_area_1, label_area_2]:\n",
    "    x.width, x.height\n",
    "    patches = round(x.width/224) * round(x.height/224)\n",
    "    total_patches += patches\n",
    "    print(total_patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 34, 256, 256)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patches_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize single patch\n",
    "show(patches_labels[5][6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(coord_labels_bounding_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patch Shape: (27, 34, 256, 256)\n",
      "CPU times: user 81 ms, sys: 78.4 ms, total: 159 ms\n",
      "Wall time: 159 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# label_area. In other projects may be referred to as mask\n",
    "patches_labels = []\n",
    "for label_area in opened_label_areas:\n",
    "    patches_labels = patchify(label_area.read(1), \n",
    "        (config.patch_size[0], config.patch_size[1]), \n",
    "        step=config.patch_size[0]-config.overlap)\n",
    "    # TODO: could also export patches to files like this:\n",
    "    # for i in range(patches_labels.shape[0]):\n",
    "    #     for j in range(patches_labels.shape[1]):\n",
    "    #         single_patch = patches_labels[i, j,:,:]\n",
    "    #         filename = opened_label_areas[0].name.replace(config.path_labeled_data_areas,\"\")[:-4] # -4 to cut off the .tif file extension\n",
    "    #         filepath_single_patch = \"{}-{}-patch-{}-{}.tif\".format(config.path_patches_masks, filename, i, j)\n",
    "    #         # gdal.Translate(filepath_single_patch, single_patch, projWin = )\n",
    "    #         # single_patch.write(filepath_single_patch)\n",
    "print(\"Patch Shape:\", patches_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create Satellite Area Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "satellige_area = satellite_img.read(1, window = from_bounds(left, bottom, right, top, satellite_img.transform))\n",
    "# Could also get coordinates from other file or from array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "window = Window(start_x, start_y, steps_x, steps_y)\n",
    "patches_satellite = patchify(satellite_img.read([1,2,3], window=window), \n",
    "    (config.patch_size[0], config.patch_size[1], 3), \n",
    "    step=config.patch_size[0]-config.overlap)\n",
    "# save patches\n",
    "print(\"Patch Shape:\", patches_satellite.shape)\n",
    "# for i in range(4): # patches.shape[0]\n",
    "#     for j in range(4): # patches.shape[1]\n",
    "#         satellite_cutouts.append(patches[i,j])\n",
    "# \n",
    "# img = cv2.imread(\"test.jpg\")\n",
    "\n",
    "\n",
    "for i in range(patches_satellite.shape[0]):\n",
    "    for j in range(patches_satellite.shape[1]):\n",
    "        single_patch = patches_satellite[i, j, 0, :, :, :]\n",
    "        satellite_cutouts.append(single_patch)\n",
    "        if not cv2.imwrite('patches/images/' + 'image_' + '_'+ str(i)+str(j)+'.jpg', single_patch):\n",
    "            raise Exception(\"Could not write the image\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    for img in range(satellite_img.shape[0]):\n",
    "        row = satellite_img[img]\n",
    "        patches = patchify(row, (config.patch_size[0], config.patch_size[1], 1), step=config.patch_size[0]-config.overlap)\n",
    "        # save patches\n",
    "        print(\"Patch Shape:\", patches.shape)\n",
    "        for i in range(4): # patches.shape[0]\n",
    "            for j in range(4): # patches.shape[1]\n",
    "                satellite_cutouts.append(patches[i,j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_frames, validation_frames, testing_frames  = split_dataset(frames, config.frames_json, config.patch_dir)\n",
    "# training_frames = validation_frames = testing_frames  = list(range(len(frames)))\n",
    "\n",
    "annotation_channels = config.input_label_channel + config.input_weight_channel\n",
    "# DataGenerator performs Data Augmentation: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
    "train_generator = DataGenerator(config.input_image_channel, config.patch_size, training_frames, frames, annotation_channels, augmenter = 'iaa').random_generator(config.BATCH_SIZE, normalize = config.normalize)\n",
    "val_generator = DataGenerator(config.input_image_channel, config.patch_size, validation_frames, frames, annotation_channels, augmenter= None).random_generator(config.BATCH_SIZE, normalize = config.normalize)\n",
    "test_generator = DataGenerator(config.input_image_channel, config.patch_size, testing_frames, frames, annotation_channels, augmenter= None).random_generator(config.BATCH_SIZE, normalize = config.normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(1):\n",
    "    train_images, real_label = next(train_generator)\n",
    "    ann = real_label[:,:,:,0]\n",
    "    wei = real_label[:,:,:,1]\n",
    "    #overlay of annotation with boundary to check the accuracy\n",
    "    #5 images in each row are: pan, ndvi, annotation, weight(boundary), overlay of annotation with weight\n",
    "    overlay = ann + wei\n",
    "    overlay = overlay[:,:,:,np.newaxis]\n",
    "    display_images(np.concatenate((train_images,real_label, overlay), axis = -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTIMIZER = adaDelta\n",
    "LOSS = tversky \n",
    "\n",
    "#Only for the name of the model in the very end\n",
    "OPTIMIZER_NAME = 'AdaDelta'\n",
    "LOSS_NAME = 'weightmap_tversky'\n",
    "\n",
    "# Declare the path to the final model\n",
    "# If you want to retrain an exising model then change the cell where model is declared. \n",
    "# This path is for storing a model after training.\n",
    "\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M\")\n",
    "chf = config.input_image_channel + config.input_label_channel\n",
    "chs = reduce(lambda a,b: a+str(b), chf, '')\n",
    "\n",
    "\n",
    "if not os.path.exists(config.model_path):\n",
    "    os.makedirs(config.model_path)\n",
    "model_path = os.path.join(config.model_path,'trees_{}_{}_{}_{}_{}.h5'.format(timestr,OPTIMIZER_NAME,LOSS_NAME,chs,config.input_shape[0]))\n",
    "\n",
    "# The weights without the model architecture can also be saved. Just saving the weights is more efficent.\n",
    "\n",
    "# weight_path=\"./saved_weights/UNet/{}/\".format(timestr)\n",
    "# if not os.path.exists(weight_path):\n",
    "#     os.makedirs(weight_path)\n",
    "# weight_path=weight_path + \"{}_weights.best.hdf5\".format('UNet_model')\n",
    "# print(weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 256, 256, 64) 1792        Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 256, 256, 64) 36928       conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 256, 256, 64) 256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 128, 128, 64) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 128, 128, 128 73856       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 128, 128, 128 147584      conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 128, 128, 128 512         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 128)  0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 64, 256)  295168      max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 64, 256)  590080      conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 64, 64, 256)  1024        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 256)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 512)  1180160     max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 512)  2359808     conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 512)  2048        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 512)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 1024) 4719616     max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 1024) 9438208     conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 32, 32, 1024) 0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 1024) 4096        up_sampling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 32, 32, 1536) 0           batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 512)  7078400     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 512)  2359808     conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 64, 64, 512)  0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 64, 64, 512)  2048        up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 64, 64, 768)  0           batch_normalization_5[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 64, 64, 256)  1769728     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 64, 256)  590080      conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 128, 128, 256 0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 128, 128, 256 1024        up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 128, 128, 384 0           batch_normalization_6[0][0]      \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 128, 128, 128 442496      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 128, 128, 128 147584      conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 256, 256, 128 0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 256, 256, 128 512         up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 256, 256, 192 0           batch_normalization_7[0][0]      \n",
      "                                                                 batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 256, 256, 64) 110656      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 256, 256, 64) 36928       conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 256, 256, 1)  65          conv2d_17[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 31,390,465\n",
      "Trainable params: 31,384,705\n",
      "Non-trainable params: 5,760\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model and compile it\n",
    "model = UNet([config.BATCH_SIZE, *config.input_shape],config.input_label_channel)\n",
    "model.compile(optimizer=OPTIMIZER, loss=LOSS, metrics=[dice_coef, dice_loss, specificity, sensitivity, accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNet([config.BATCH_SIZE, *config.input_shape],config.input_label_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks for the early stopping of training, LearningRateScheduler and model checkpointing\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint(model_path, monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='min', save_weights_only = False)\n",
    "\n",
    "#reduceonplatea; It can be useful when using adam as optimizer\n",
    "#Reduce learning rate when a metric has stopped improving (after some patience,reduce by a factor of 0.33, new_lr = lr * factor).\n",
    "#cooldown: number of epochs to wait before resuming normal operation after lr has been reduced.\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.33,\n",
    "                                   patience=4, verbose=1, mode='min',\n",
    "                                   min_delta=0.0001, cooldown=4, min_lr=1e-16)\n",
    "\n",
    "#early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", verbose=2, patience=15)\n",
    "\n",
    "log_dir = os.path.join('./logs','UNet_{}_{}_{}_{}_{}'.format(timestr,OPTIMIZER_NAME,LOSS_NAME,chs, config.input_shape[0]))\n",
    "tensorboard = TensorBoard(log_dir=log_dir, histogram_freq=0, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None, embeddings_data=None, update_freq='epoch')\n",
    "\n",
    "callbacks_list = [checkpoint, tensorboard] #reduceLROnPlat is not required with adaDelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cutouts lists deleted.\n"
     ]
    }
   ],
   "source": [
    "def reset_cutouts():\n",
    "    satellite_cutouts = satellite_cutouts = []\n",
    "    print(\"Cutouts lists deleted.\")\n",
    "# reset_cutouts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history = [model.fit(satellite_cutouts, # array of img with shape of [(None, 512, 512, 4)] # train_generator\n",
    "                         steps_per_epoch=config.MAX_TRAIN_STEPS, \n",
    "                         epochs=config.NB_EPOCHS, \n",
    "                         validation_data=satellite_cutouts,\n",
    "                         validation_steps=config.VALID_IMG_COUNT,\n",
    "                         callbacks=callbacks_list,\n",
    "                         workers=1,\n",
    "#                         use_multiprocessing=True # the generator is not very thread safe\n",
    "                        )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from patchify import patchify\n",
    "\n",
    "satellite_img = rasterio.open(config.filepath_satellite)\n",
    "label_img = rasterio.open(config.filepath_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.1 s, sys: 28.2 s, total: 46.4 s\n",
      "Wall time: 53.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 107798, 54112)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "start_x = start_y = 0\n",
    "# load the west half of the satellite image\n",
    "steps_x = satellite_img.shape[1] / 2\n",
    "steps_y = satellite_img.shape[0] # / 2\n",
    "window = Window(start_x, start_y, steps_x, steps_y)\n",
    "read_sat_west_half = satellite_img.read([1,2,3], window=window)\n",
    "read_sat_west_half.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.1 s, sys: 32.4 s, total: 51.5 s\n",
      "Wall time: 1min 8s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 107798, 54112)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# load the east half of the satellite image\n",
    "start_x = steps_x\n",
    "steps_x = satellite_img.shape[1] - steps_x # if size in px is uneven\n",
    "window = Window(start_x, start_y, steps_x, steps_y)\n",
    "read_sat_east_half = satellite_img.read([1,2,3], window=window)\n",
    "read_sat_east_half.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat numpy patches array\n",
    "# read_sat = np.concatenate((read_sat_west_half, read_sat_east_half))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 107798, 54112), (3, 107798, 54112))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_sat_west_half.shape, read_sat_east_half.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change so that it uses 512 px img instead of 256\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "def UNet(input_shape, input_label_channel, layer_count=64, regularizers = regularizers.l2(0.0001), gaussian_noise=0.1, weight_file = None):\n",
    "        \"\"\" Method to declare the UNet model.\n",
    "\n",
    "        Args:\n",
    "            input_shape: tuple(int, int, int, int)\n",
    "                Shape of the input in the format (batch, height, width, channels).\n",
    "            input_label_channel: list([int])\n",
    "                list of index of label channels, used for calculating the number of channels in model output.\n",
    "            layer_count: (int, optional)\n",
    "                Count of kernels in first layer. Number of kernels in other layers grows with a fixed factor.\n",
    "            regularizers: keras.regularizers\n",
    "                regularizers to use in each layer.\n",
    "            weight_file: str\n",
    "                path to the weight file.\n",
    "        \"\"\"\n",
    "\n",
    "        input_img = layers.Input(input_shape[1:], name='Input')\n",
    "        pp_in_layer  = input_img\n",
    "#        pp_in_layer = layers.GaussianNoise(gaussian_noise)(input_img)\n",
    "#        pp_in_layer = layers.BatchNormalization()(pp_in_layer)\n",
    "\n",
    "\n",
    "        c1 = layers.Conv2D(1*layer_count, (3, 3), activation='relu', padding='same')(pp_in_layer)\n",
    "        c1 = layers.Conv2D(1*layer_count, (3, 3), activation='relu', padding='same')(c1)\n",
    "        n1 = layers.BatchNormalization()(c1)\n",
    "        p1 = layers.MaxPooling2D((2, 2))(n1)\n",
    "\n",
    "        c2 = layers.Conv2D(2*layer_count, (3, 3), activation='relu', padding='same')(p1)\n",
    "        c2 = layers.Conv2D(2*layer_count, (3, 3), activation='relu', padding='same')(c2)\n",
    "        n2 = layers.BatchNormalization()(c2)\n",
    "        p2 = layers.MaxPooling2D((2, 2))(n2)\n",
    "\n",
    "        c3 = layers.Conv2D(4*layer_count, (3, 3), activation='relu', padding='same')(p2)\n",
    "        c3 = layers.Conv2D(4*layer_count, (3, 3), activation='relu', padding='same')(c3)\n",
    "        n3 = layers.BatchNormalization()(c3)\n",
    "        p3 = layers.MaxPooling2D((2, 2))(n3)\n",
    "\n",
    "        c4 = layers.Conv2D(8*layer_count, (3, 3), activation='relu', padding='same')(p3)\n",
    "        c4 = layers.Conv2D(8*layer_count, (3, 3), activation='relu', padding='same')(c4)\n",
    "        n4 = layers.BatchNormalization()(c4)\n",
    "        p4 = layers.MaxPooling2D(pool_size=(2, 2))(n4)\n",
    "\n",
    "        c5 = layers.Conv2D(16*layer_count, (3, 3), activation='relu', padding='same')(p4)\n",
    "        c5 = layers.Conv2D(16*layer_count, (3, 3), activation='relu', padding='same')(c5)\n",
    "\n",
    "        u6 = layers.UpSampling2D((2, 2))(c5)\n",
    "        n6 = layers.BatchNormalization()(u6)\n",
    "        u6 = layers.concatenate([n6, n4])\n",
    "        c6 = layers.Conv2D(8*layer_count, (3, 3), activation='relu', padding='same')(u6)\n",
    "        c6 = layers.Conv2D(8*layer_count, (3, 3), activation='relu', padding='same')(c6)\n",
    "\n",
    "        u7 = layers.UpSampling2D((2, 2))(c6)\n",
    "        n7 = layers.BatchNormalization()(u7)\n",
    "        u7 = layers.concatenate([n7, n3])\n",
    "        c7 = layers.Conv2D(4*layer_count, (3, 3), activation='relu', padding='same')(u7)\n",
    "        c7 = layers.Conv2D(4*layer_count, (3, 3), activation='relu', padding='same')(c7)\n",
    "\n",
    "        u8 = layers.UpSampling2D((2, 2))(c7)\n",
    "        n8 = layers.BatchNormalization()(u8)\n",
    "        u8 = layers.concatenate([n8, n2])\n",
    "        c8 = layers.Conv2D(2*layer_count, (3, 3), activation='relu', padding='same')(u8)\n",
    "        c8 = layers.Conv2D(2*layer_count, (3, 3), activation='relu', padding='same')(c8)\n",
    "\n",
    "        u9 = layers.UpSampling2D((2, 2))(c8)\n",
    "        n9 = layers.BatchNormalization()(u9)\n",
    "        u9 = layers.concatenate([n9, n1], axis=3)\n",
    "        c9 = layers.Conv2D(1*layer_count, (3, 3), activation='relu', padding='same')(u9)\n",
    "        c9 = layers.Conv2D(1*layer_count, (3, 3), activation='relu', padding='same')(c9)\n",
    "\n",
    "        d = layers.Conv2D(len(input_label_channel), (1, 1), activation='sigmoid', kernel_regularizer= regularizers)(c9)\n",
    "\n",
    "        seg_model = models.Model(inputs=[input_img], outputs=[d])\n",
    "        if weight_file:\n",
    "            seg_model.load_weights(weight_file)\n",
    "        seg_model.summary()\n",
    "        return seg_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. YT Video: Preview of Test Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load previously saved model\n",
    "from keras.models import load_model\n",
    "# model = load_model(\"/content/drive/MyDrive/Colab Notebooks/saved_models/tutorial118_mitochondria_25epochs.hdf5\", compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IOU\n",
    "y_pred=model.predict(X_test)\n",
    "# if model is more than 50% sure it is a cell, it returns True, else False\n",
    "y_pred_thresholded = y_pred > 0.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import MeanIoU\n",
    "n_classes = 2\n",
    "IOU_keras = MeanIoU(num_classes=n_classes)  \n",
    "IOU_keras.update_state(y_pred_thresholded, y_test)\n",
    "print(\"Mean IoU =\", IOU_keras.result().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "test_img_number = random.randint(0, len(X_test)-1)\n",
    "test_img = X_test[test_img_number]\n",
    "ground_truth=y_test[test_img_number]\n",
    "test_img_input=np.expand_dims(test_img, 0)\n",
    "print(test_img_input.shape)\n",
    "prediction = (model.predict(test_img_input)[0,:,:,0] > 0.5).astype(np.uint8)\n",
    "print(prediction.shape)\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(231)\n",
    "plt.title('Testing Image')\n",
    "plt.imshow(test_img[:,:,0], cmap='gray')\n",
    "plt.subplot(232)\n",
    "plt.title('Testing Label')\n",
    "plt.imshow(ground_truth[:,:,0], cmap='gray')\n",
    "plt.subplot(233)\n",
    "plt.title('Prediction on test image')\n",
    "plt.imshow(prediction, cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
