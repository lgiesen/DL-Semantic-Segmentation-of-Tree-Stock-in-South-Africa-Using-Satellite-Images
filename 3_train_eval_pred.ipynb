{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config\n",
    "from config import UNetTraining\n",
    "# from config import UNetTraining\n",
    "config = UNetTraining.Configuration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import colors\n",
    "colors = colors.bcolors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import rasterio\n",
    "# from rasterio.windows import Window\n",
    "\n",
    "# import imgaug as ia\n",
    "# from imgaug import augmenters as iaa\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "import time\n",
    "import rasterio.warp # Reproject raster samples\n",
    "from functools import reduce\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from core.UNet import UNet\n",
    "from core.losses import tversky, accuracy, dice_coef, dice_loss, specificity, sensitivity\n",
    "from core.optimizers import adaDelta #, adagrad, adam, nadam\n",
    "# from core.frame_info import FrameInfo\n",
    "# from core.dataset_generator import DataGenerator\n",
    "# from core.split_frames import split_dataset\n",
    "# from core.visualize import display_images\n",
    "\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt  # plotting tools\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.patches import Polygon\n",
    "\n",
    "import warnings                  # ignore annoying warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import platform\n",
    "\n",
    "if platform == \"linux\" or platform == \"linux2\":\n",
    "    path_satellite = \"/home/jovyan/work/satellite_data/\"\n",
    "    path_labels = os.getcwd() + \"/1_labeled_data/tif/\"\n",
    "    cutouts_path = os.getcwd() + \"/2_cutouts/\"\n",
    "elif platform == \"darwin\":\n",
    "    path_data = \"/Users/leori/Desktop/BA/1_Data/\"\n",
    "    path_satellite = path_data + \"2_satellite/\"\n",
    "    path_labels = path_data + \"1_labeled_data/tif/\"\n",
    "    cutouts_path = None\n",
    "elif platform == \"win32\":\n",
    "    print(\"Something went wrong\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Label Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "labels_bounding_boxes = gpd.read_file(config.filepath_labels_bounding_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get polygon coordinates \n",
    "import json\n",
    "g = json.loads(labels_bounding_boxes.to_json())\n",
    "coords = []\n",
    "for polygon in range(len(g)):\n",
    "    coords.append(g['features'][polygon]['geometry']['coordinates'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasterio.windows import from_bounds\n",
    "from rasterio.plot import show\n",
    "# visualize labels\n",
    "src_label = rasterio.open(config.filepath_label)\n",
    "labels = []\n",
    "coord_labels_bounding_boxes = []\n",
    "for polygon in range(len(g)):\n",
    "    west, south = coords[polygon][0][0], coords[polygon][0][1]\n",
    "    east, north = coords[polygon][2][0], coords[polygon][2][1]\n",
    "    coord_labels_bounding_boxes.append((west, south, east, north))\n",
    "    print(polygon, \":\", coord_labels_bounding_boxes[polygon])\n",
    "    labels.append(src_label.read(1, window = from_bounds(west, south, east, north, src_label.transform)))\n",
    "    show(labels[polygon])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal\n",
    "\n",
    "label_file = gdal.Open(config.filepath_label)\n",
    "filepath_labeled_areas = []\n",
    "for polygon in range(len(g)):\n",
    "    # same coordinates as above\n",
    "    west, south = coords[polygon][0][0], coords[polygon][0][1]\n",
    "    east, north = coords[polygon][2][0], coords[polygon][2][1]\n",
    "    # gdal only needs the coordingates in a different order\n",
    "    coord_labels_bounding_boxes.append((west, south, east, north))\n",
    "\n",
    "    filepath_labeled_area = config.path_labeled_data_areas + \"label-area-\" + str(polygon) + \".tif\"\n",
    "    filepath_labeled_areas.append(filepath_labeled_area)\n",
    "    cropped_window = (west,north,east,south) # coord_labels_bounding_boxes[polygon]\n",
    "    # print(filepath_labeled_area)\n",
    "    print(cropped_window)\n",
    "    gdal.Translate(filepath_labeled_area, label_file, projWin = cropped_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close rasterio & gdal dataset\n",
    "src_label.close() \n",
    "del label_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Correction & Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust data: Data was somehow misexported so that some polygons were gray instead of black\n",
    "# Satellite: value/255 or scaler\n",
    "# Labels: if not 0: set to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "# scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "# X_scaled = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patchify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Label Area Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_area_1 = rasterio.open(filepath_labeled_areas[0])\n",
    "label_area_2 = rasterio.open(filepath_labeled_areas[1])\n",
    "opened_label_areas = [label_area_1, label_area_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_patches = 0\n",
    "for label_area in opened_label_areas:\n",
    "    label_area.width, label_area.height\n",
    "    patches = round(label_area.width/224) * round(label_area.height/224)\n",
    "    total_patches += patches\n",
    "    print(total_patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(coord_labels_bounding_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from patchify import patchify\n",
    "\n",
    "satellite_img = rasterio.open(config.filepath_satellite)\n",
    "label_img = rasterio.open(config.filepath_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# label_area. In other projects may be referred to as mask\n",
    "patches_labels = []\n",
    "for label_area in opened_label_areas:\n",
    "    patches_labels = patchify(label_area.read(1), \n",
    "        (config.patch_size[0], config.patch_size[1]), \n",
    "        step=config.patch_size[0]-config.overlap)\n",
    "    # TODO: could also export patches to files like this:\n",
    "    for i in range(patches_labels.shape[0]):\n",
    "        for j in range(patches_labels.shape[1]):\n",
    "            single_patch = patches_labels[i, j,:,:]\n",
    "    #         filename = opened_label_areas[0].name.replace(config.path_labeled_data_areas,\"\")[:-4] # -4 to cut off the .tif file extension\n",
    "    #         filepath_single_patch = \"{}-{}-patch-{}-{}.tif\".format(config.path_patches_masks, filename, i, j)\n",
    "    #         # gdal.Translate(filepath_single_patch, single_patch, projWin = )\n",
    "    #         # single_patch.write(filepath_single_patch)\n",
    "print(\"Mask/Label Patch Shape:\", patches_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patches_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize single patch\n",
    "show(patches_labels[17][16])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Satellite Area Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "patches_satellite = []\n",
    "for index, label_area in enumerate(opened_label_areas):\n",
    "    # get coordinates\n",
    "    cur_coords = coord_labels_bounding_boxes[index]\n",
    "    (west, south, east, north) = cur_coords\n",
    "    print(cur_coords)\n",
    "    \n",
    "    satellite_area = satellite_img.read([1,2,3], window = from_bounds(west, south, east, north, satellite_img.transform))\n",
    "    \n",
    "    cropped_window = (west,north,east,south)\n",
    "    filename = opened_label_areas[0].name.replace(config.path_labeled_data_areas,\"\")[6:-4] # -4 to cut off the .tif file extension and 6 to cut off label\n",
    "    filepath_satellite_area = \"{}areas/{}.tif\".format(config.path_patches_satellite, filename)\n",
    "\n",
    "    patches_satellite = patchify(satellite_area, \n",
    "        (3, config.patch_size[0], config.patch_size[1]), \n",
    "        step=config.patch_size[0]-config.overlap)[0]\n",
    "    \n",
    "    # or reshape now:\n",
    "    # satellite_area_reshaped = np.reshape(satellite_area, (satellite_area.shape[1],satellite_area.shape[2],3))\n",
    "    # patches_satellite = patchify(satellite_area_reshaped, \n",
    "    #     (config.patch_size[0], config.patch_size[1], 3), \n",
    "    #     step=config.patch_size[0]-config.overlap)[0]\n",
    "\n",
    "    # TODO: SAVE TO SEPARATE IMG + LOAD IT\n",
    "    # gdal.Translate(filepath_satellite_area, satellite_area, projWin = cropped_window)\n",
    "    # could also export patches to files like this:\n",
    "    # for i in range(patches_satellite.shape[0]):\n",
    "    #     for j in range(patches_satellite.shape[1]):\n",
    "    #         single_patch = patches_satellite[i, j,:,:]\n",
    "    #         filename = opened_label_areas[0].name.replace(config.path_labeled_data_areas,\"\")[:-4] # -4 to cut off the .tif file extension\n",
    "    #         filepath_single_patch = \"{}-{}-patch-{}-{}.tif\".format(config.path_patches_masks, filename, i, j)\n",
    "    #         # gdal.Translate(filepath_single_patch, single_patch, projWin = )\n",
    "    #         # single_patch.write(filepath_single_patch)\n",
    "print(\"Satellite Patch Shape:\", patches_satellite.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_area.read(1).shape\n",
    "satellite_area.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "satellite_area_reshaped = np.reshape(satellite_area, (satellite_area.shape[1],satellite_area.shape[2],3))\n",
    "satellite_area_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patches_labels.shape\n",
    "patches_satellite.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation & Feature Scaling (still to do)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTIMIZER = adaDelta\n",
    "LOSS = tversky \n",
    "\n",
    "#Only for the name of the model in the very end\n",
    "OPTIMIZER_NAME = 'AdaDelta'\n",
    "LOSS_NAME = 'weightmap_tversky'\n",
    "\n",
    "# Declare the path to the final model\n",
    "# If you want to retrain an exising model then change the cell where model is declared. \n",
    "# This path is for storing a model after training.\n",
    "\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M\")\n",
    "chf = config.input_image_channel + config.input_label_channel\n",
    "chs = reduce(lambda a,b: a+str(b), chf, '')\n",
    "\n",
    "\n",
    "if not os.path.exists(config.model_path):\n",
    "    os.makedirs(config.model_path)\n",
    "model_path = os.path.join(config.model_path,'trees_{}_{}_{}_{}_{}.h5'.format(timestr,OPTIMIZER_NAME,LOSS_NAME,chs,config.input_shape[0]))\n",
    "\n",
    "# The weights without the model architecture can also be saved. Just saving the weights is more efficent.\n",
    "\n",
    "# weight_path=\"./saved_weights/UNet/{}/\".format(timestr)\n",
    "# if not os.path.exists(weight_path):\n",
    "#     os.makedirs(weight_path)\n",
    "# weight_path=weight_path + \"{}_weights.best.hdf5\".format('UNet_model')\n",
    "# print(weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model and compile it\n",
    "model = UNet([config.BATCH_SIZE, *config.input_shape],config.input_label_channel)\n",
    "model.compile(optimizer=OPTIMIZER, loss=LOSS, metrics=[dice_coef, dice_loss, specificity, sensitivity, accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks for the early stopping of training, LearningRateScheduler and model checkpointing\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint(model_path, monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='min', save_weights_only = False)\n",
    "\n",
    "#reduceonplatea; It can be useful when using adam as optimizer\n",
    "#Reduce learning rate when a metric has stopped improving (after some patience,reduce by a factor of 0.33, new_lr = lr * factor).\n",
    "#cooldown: number of epochs to wait before resuming normal operation after lr has been reduced.\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.33,\n",
    "                                   patience=4, verbose=1, mode='min',\n",
    "                                   min_delta=0.0001, cooldown=4, min_lr=1e-16)\n",
    "\n",
    "#early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", verbose=2, patience=15)\n",
    "\n",
    "log_dir = os.path.join('./logs','UNet_{}_{}_{}_{}_{}'.format(timestr,OPTIMIZER_NAME,LOSS_NAME,chs, config.input_shape[0]))\n",
    "tensorboard = TensorBoard(log_dir=log_dir, histogram_freq=0, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None, embeddings_data=None, update_freq='epoch')\n",
    "\n",
    "callbacks_list = [checkpoint, tensorboard] #reduceLROnPlat is not required with adaDelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation for Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshape Patches to Fit to the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patches_satellite.shape\n",
    "patches_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = patches_satellite.shape\n",
    "patches_satellite_reshaped = patches_satellite.reshape(shape[0]*shape[1], shape[2], shape[3], shape[4])\n",
    "patches_satellite_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = patches_labels.shape\n",
    "patches_labels_reshaped = patches_labels.reshape(shape[0]*shape[1], shape[2], shape[3])\n",
    "patches_labels_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the color values\n",
    "patches_satellite_training = np.where(True, patches_satellite_reshaped / 255, patches_satellite_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make all values of the array which are not 0, 1. Either label or no label. \n",
    "# This has to be performed, because the exported labels have color values, which have to be normalized. \n",
    "# Somehow, some color values have been above 255, which might have happened due to a faulty export from QGIS. \n",
    "patches_labels_training = np.where(patches_labels_reshaped != 0.0, 1.0, patches_labels_reshaped)\n",
    "# conversion to the same type as patches_satellite_training ('float64')\n",
    "patches_labels_training = patches_labels_training.astype(patches_satellite_training.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Training and Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(patches_satellite_training, patches_labels_training, test_size=config.test_ratio, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [X_train, X_test, y_train, y_test]:\n",
    "    i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check: check if satellite and label data matches\n",
    "x = 16\n",
    "show(X_train[x])\n",
    "show(y_train[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reshaped = X_train.reshape(X_train.shape[0], X_train.shape[2], X_train.shape[3], X_train.shape[1])\n",
    "X_test_reshaped = X_test.reshape(X_test.shape[0], X_test.shape[2], X_test.shape[3], X_test.shape[1])\n",
    "# X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Maybe Model defined to only receive one input and not rgb => test out or look into model | but project has 2 color channels\n",
    "- maybe data generator adjusts data? But does not affect model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  38/1000 [>.............................] - ETA: 5:20:56 - loss: 0.6769 - dice_coef: 0.0251 - dice_loss: 0.9749 - specificity: 0.0433 - sensitivity: nan - accuracy: 0.0554"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "loss_history = [model.fit(x=X_train_reshaped,\n",
    "                        y=y_train,\n",
    "                        epochs=config.NB_EPOCHS, \n",
    "                        # validation_data=y_train,\n",
    "                        steps_per_epoch=config.MAX_TRAIN_STEPS,\n",
    "                        # validation_steps=config.VALID_IMG_COUNT,\n",
    "                        batch_size=config.BATCH_SIZE,\n",
    "                        callbacks=callbacks_list,\n",
    "                        # workers=1,\n",
    "                        # use_multiprocessing=True # the generator is not very thread safe\n",
    "                )]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test_reshaped, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%script false\n",
    "#Plot accuracy and loss of train and val set\n",
    "plt.rcParams.update({'font.family':'serif'})\n",
    "\n",
    "plt.figure(figsize=(11,4))\n",
    "plt.subplot(121)\n",
    "plt.plot(loss_history.history['accuracy'], color=\"green\")\n",
    "plt.plot(loss_history.history['val_accuracy'], color=\"blue\")\n",
    "plt.title(\"Accuracy\", fontsize=16)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(['train', 'val'], loc='lower right')\n",
    "plt.subplot(122)\n",
    "plt.plot(loss_history.history['loss'], color=\"red\",)\n",
    "plt.plot(loss_history.history['val_loss'], color=\"orange\")\n",
    "plt.title(\"Loss\", fontsize=16)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train', 'val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"accuracy: \" + str(loss_history.history['accuracy'][-1]))\n",
    "print(\"loss:     \" + str(loss_history.history['loss'][-1]))\n",
    "\n",
    "print(\"Validation\")\n",
    "print(\"accuracy: \" + str(loss_history.history['val_accuracy'][-1]))\n",
    "print(\"loss:     \" + str(loss_history.history['val_loss'][-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%script false\n",
    "# base_model = keras.models.load_model('pathtomodel/own_trainingData_210714.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. YT Video: Preview of Test Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load previously saved model\n",
    "from keras.models import load_model\n",
    "# model = load_model(\"/content/drive/MyDrive/Colab Notebooks/saved_models/tutorial118_mitochondria_25epochs.hdf5\", compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IOU\n",
    "y_pred=model.predict(X_test)\n",
    "# if model is more than 50% sure it is a cell, it returns True, else False\n",
    "y_pred_thresholded = y_pred > 0.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import MeanIoU\n",
    "n_classes = 2\n",
    "IOU_keras = MeanIoU(num_classes=n_classes)  \n",
    "IOU_keras.update_state(y_pred_thresholded, y_test)\n",
    "print(\"Mean IoU =\", IOU_keras.result().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "test_img_number = random.randint(0, len(X_test)-1)\n",
    "test_img = X_test[test_img_number]\n",
    "ground_truth=y_test[test_img_number]\n",
    "test_img_input=np.expand_dims(test_img, 0)\n",
    "print(test_img_input.shape)\n",
    "prediction = (model.predict(test_img_input)[0,:,:,0] > 0.5).astype(np.uint8)\n",
    "print(prediction.shape)\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(231)\n",
    "plt.title('Testing Image')\n",
    "plt.imshow(test_img[:,:,0], cmap='gray')\n",
    "plt.subplot(232)\n",
    "plt.title('Testing Label')\n",
    "plt.imshow(ground_truth[:,:,0], cmap='gray')\n",
    "plt.subplot(233)\n",
    "plt.title('Prediction on test image')\n",
    "plt.imshow(prediction, cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
