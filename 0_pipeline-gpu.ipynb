{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import config\n",
    "config = config.Configuration()\n",
    "run_prev_notebooks = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import rasterio\n",
    "# from rasterio.windows import Window\n",
    "\n",
    "import os\n",
    "import time\n",
    "import rasterio.warp # Reproject raster samples\n",
    "from functools import reduce\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from core.losses import tversky, accuracy, dice_coef, dice_loss, specificity, sensitivity\n",
    "from core.optimizers import adaDelta #, adagrad, adam, nadam\n",
    "\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.patches import Polygon\n",
    "\n",
    "import warnings # ignore annoying warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define_model()# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preparation():\n",
    "    print(\"1: Data_preparation\") \n",
    "    %run \"1_data_preparation.ipynb\"\n",
    "def define_model():\n",
    "    print(\"2: Model\")\n",
    "    %run \"2_model.ipynb\"\n",
    "def training():\n",
    "    print(\"3: Training\")\n",
    "    %run \"3_training.ipynb\"\n",
    "def evaluation():\n",
    "    print(\"4: Evaluation\")\n",
    "    %run \"4_evaluation.ipynb\"\n",
    "def prediction():\n",
    "    print(\"5: Prediction\")\n",
    "    %run \"5_prediction.ipynb\"\n",
    "def data_cleanup():\n",
    "    print(\"6: Data Cleanup\")\n",
    "    %run \"6_data_cleanup.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Data_preparation\n",
      "2: Model\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Input (InputLayer)             [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 256, 256, 64  1792        ['Input[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 256, 256, 64  36928       ['conv2d[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 256, 256, 64  256        ['conv2d_1[0][0]']               \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 128, 128, 64  0           ['batch_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 128, 128, 12  73856       ['max_pooling2d[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 128, 128, 12  147584      ['conv2d_2[0][0]']               \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 128, 128, 12  512        ['conv2d_3[0][0]']               \n",
      " rmalization)                   8)                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 128)  0          ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 64, 64, 256)  295168      ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 64, 64, 256)  590080      ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 64, 64, 256)  1024       ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 256)  0          ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 32, 32, 512)  1180160     ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 32, 32, 512)  2359808     ['conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 32, 32, 512)  2048       ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 512)  0          ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 16, 16, 1024  4719616     ['max_pooling2d_3[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 16, 16, 1024  9438208     ['conv2d_8[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2D)   (None, 32, 32, 1024  0           ['conv2d_9[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 32, 32, 1024  4096       ['up_sampling2d[0][0]']          \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 32, 32, 1536  0           ['batch_normalization_4[0][0]',  \n",
      "                                )                                 'batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 32, 32, 512)  7078400     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 32, 32, 512)  2359808     ['conv2d_10[0][0]']              \n",
      "                                                                                                  \n",
      " up_sampling2d_1 (UpSampling2D)  (None, 64, 64, 512)  0          ['conv2d_11[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 64, 64, 512)  2048       ['up_sampling2d_1[0][0]']        \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 64, 64, 768)  0           ['batch_normalization_5[0][0]',  \n",
      "                                                                  'batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 64, 64, 256)  1769728     ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 64, 64, 256)  590080      ['conv2d_12[0][0]']              \n",
      "                                                                                                  \n",
      " up_sampling2d_2 (UpSampling2D)  (None, 128, 128, 25  0          ['conv2d_13[0][0]']              \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 128, 128, 25  1024       ['up_sampling2d_2[0][0]']        \n",
      " rmalization)                   6)                                                                \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 128, 128, 38  0           ['batch_normalization_6[0][0]',  \n",
      "                                4)                                'batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 128, 128, 12  442496      ['concatenate_2[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 128, 128, 12  147584      ['conv2d_14[0][0]']              \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " up_sampling2d_3 (UpSampling2D)  (None, 256, 256, 12  0          ['conv2d_15[0][0]']              \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 256, 256, 12  512        ['up_sampling2d_3[0][0]']        \n",
      " rmalization)                   8)                                                                \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 256, 256, 19  0           ['batch_normalization_7[0][0]',  \n",
      "                                2)                                'batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 256, 256, 64  110656      ['concatenate_3[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 256, 256, 64  36928       ['conv2d_16[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 256, 256, 1)  65          ['conv2d_17[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 31,390,465\n",
      "Trainable params: 31,384,705\n",
      "Non-trainable params: 5,760\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "data_preparation()\n",
    "define_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__CUDNN VERSION: 8005\n",
      "__Number CUDA Devices: 3\n",
      "__CUDA Device Name: GeForce RTX 3090\n",
      "__CUDA Device Total Memory [GB]: 25.447170048\n"
     ]
    }
   ],
   "source": [
    "if use_cuda:\n",
    "    print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "    print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "    print('__CUDA Device Name:',torch.cuda.get_device_name(0))\n",
    "    print('__CUDA Device Total Memory [GB]:',torch.cuda.get_device_properties(0).total_memory/1e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-9528bf005a1e>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "GPU is available: False. List of GPUs: []\n"
     ]
    }
   ],
   "source": [
    "print(f\"GPU is available: {tf.test.is_gpu_available()}. List of GPUs: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "# device = torch.device(\"cuda:2\" if use_cuda else \"cpu\")\n",
    "print(\"Device: \",device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare Data for GPU Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2349, shape=(), dtype=int64)\n",
      "tf.Tensor(588, shape=(), dtype=int64)\n",
      "tf.Tensor(735, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "\n",
    "print(tf.data.experimental.cardinality(train_ds))\n",
    "print(tf.data.experimental.cardinality(val_ds))\n",
    "print(tf.data.experimental.cardinality(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_t = torch.FloatTensor(X_train)\n",
    "y_train_t = torch.FloatTensor(y_train)\n",
    "\n",
    "X_test_t = torch.FloatTensor(X_test)\n",
    "y_test_t = torch.FloatTensor(y_test)\n",
    "\n",
    "X_val_t = torch.FloatTensor(X_val)\n",
    "y_val_t = torch.FloatTensor(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move Data to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, y_train = torch.tensor(X_train).to(device), torch.tensor(y_train).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Input (InputLayer)             [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 256, 256, 64  1792        ['Input[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 256, 256, 64  36928       ['conv2d_20[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 256, 256, 64  256        ['conv2d_21[0][0]']              \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 128, 128, 64  0          ['batch_normalization_8[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 128, 128, 12  73856       ['max_pooling2d_4[0][0]']        \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 128, 128, 12  147584      ['conv2d_22[0][0]']              \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 128, 128, 12  512        ['conv2d_23[0][0]']              \n",
      " rmalization)                   8)                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPooling2D)  (None, 64, 64, 128)  0          ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 64, 64, 256)  295168      ['max_pooling2d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 64, 64, 256)  590080      ['conv2d_24[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 64, 64, 256)  1024       ['conv2d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_6 (MaxPooling2D)  (None, 32, 32, 256)  0          ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 32, 32, 512)  1180160     ['max_pooling2d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 32, 32, 512)  2359808     ['conv2d_26[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 32, 32, 512)  2048       ['conv2d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_7 (MaxPooling2D)  (None, 16, 16, 512)  0          ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 16, 16, 1024  4719616     ['max_pooling2d_7[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 16, 16, 1024  9438208     ['conv2d_28[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " up_sampling2d_4 (UpSampling2D)  (None, 32, 32, 1024  0          ['conv2d_29[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 32, 32, 1024  4096       ['up_sampling2d_4[0][0]']        \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 32, 32, 1536  0           ['batch_normalization_12[0][0]', \n",
      "                                )                                 'batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 32, 32, 512)  7078400     ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 32, 32, 512)  2359808     ['conv2d_30[0][0]']              \n",
      "                                                                                                  \n",
      " up_sampling2d_5 (UpSampling2D)  (None, 64, 64, 512)  0          ['conv2d_31[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 64, 64, 512)  2048       ['up_sampling2d_5[0][0]']        \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 64, 64, 768)  0           ['batch_normalization_13[0][0]', \n",
      "                                                                  'batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 64, 64, 256)  1769728     ['concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 64, 64, 256)  590080      ['conv2d_32[0][0]']              \n",
      "                                                                                                  \n",
      " up_sampling2d_6 (UpSampling2D)  (None, 128, 128, 25  0          ['conv2d_33[0][0]']              \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 128, 128, 25  1024       ['up_sampling2d_6[0][0]']        \n",
      " ormalization)                  6)                                                                \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 128, 128, 38  0           ['batch_normalization_14[0][0]', \n",
      "                                4)                                'batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 128, 128, 12  442496      ['concatenate_6[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 128, 128, 12  147584      ['conv2d_34[0][0]']              \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " up_sampling2d_7 (UpSampling2D)  (None, 256, 256, 12  0          ['conv2d_35[0][0]']              \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 256, 256, 12  512        ['up_sampling2d_7[0][0]']        \n",
      " ormalization)                  8)                                                                \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 256, 256, 19  0           ['batch_normalization_15[0][0]', \n",
      "                                2)                                'batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 256, 256, 64  110656      ['concatenate_7[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 256, 256, 64  36928       ['conv2d_36[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 256, 256, 1)  65          ['conv2d_37[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 31,390,465\n",
      "Trainable params: 31,384,705\n",
      "Non-trainable params: 5,760\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from core.UNet_class import UNetModel\n",
    "\n",
    "class MyModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Some init for my module\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Function for performing the calculation of the module.\n",
    "        pass\n",
    "\n",
    "shape_input = tf.convert_to_tensor(np.array([config.BATCH_SIZE, *config.input_shape]))\n",
    "model = UNetModel(shape_input, [config.input_shape[-1]])\n",
    "#shape_input = torch.tensor(np.array([config.BATCH_SIZE, *config.input_shape]))\n",
    "#tf.convert_to_tensor\n",
    "#model = UNetModel(shape_input,config.input_label_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainingsdata is on: cuda:1 - True\n"
     ]
    }
   ],
   "source": [
    "print(f\"Trainingsdata is on: {X_train.device} - {X_train.is_cuda}\")\n",
    "# print(f\"Model is on: {model.device} - {model.is_cuda}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.losses import tversky, accuracy, dice_coef, dice_loss, specificity, sensitivity\n",
    "from core.optimizers import adaDelta\n",
    "from functools import reduce\n",
    "\n",
    "\n",
    "OPTIMIZER = adaDelta\n",
    "LOSS = tversky \n",
    "\n",
    "#Only for the name of the model in the very end\n",
    "OPTIMIZER_NAME = 'AdaDelta'\n",
    "LOSS_NAME = 'weightmap_tversky'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs=config.NB_EPOCHS,lr=0.001,model=model,train_loader=train_ds,val_loader=val_ds,opt_func=OPTIMIZER, batch_size=config.BATCH_SIZE):\n",
    "    history = []\n",
    "    optimizer = opt_func\n",
    "    for epoch in range(epochs):\n",
    "        #training phase\n",
    "        for batch in range(batch_size):\n",
    "            loss = model.training_step(batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        #Validation phase\n",
    "        result = evaluate(model,val_loader)\n",
    "        model.epoch_end(epoch,result)# Result after each epoch\n",
    "        history.append(result)\n",
    "    return history\n",
    "def evaluate(model,val_loader):\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-01af8c4b8424>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m fit(train_loader=train_ds,\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNB_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mval_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-dfc7651f06fd>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, lr, model, train_loader, val_loader, opt_func, batch_size)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m#training phase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "fit(train_loader=train_ds,\n",
    "    epochs=config.NB_EPOCHS,\n",
    "    lr=0.001,\n",
    "    model=model,\n",
    "    val_loader=val_ds,\n",
    "    #steps_per_epoch=config.MAX_TRAIN_STEPS,\n",
    "    # validation_steps=config.VALID_IMG_COUNT,\n",
    "    batch_size=config.BATCH_SIZE,\n",
    "    #callbacks=callbacks_list\n",
    "    # workers=1,\n",
    "    # use_multiprocessing=True # the generator is not very thread safe\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleAttributeError",
     "evalue": "'UNetModel' object has no attribute 'fit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleAttributeError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-bc4e6549b604>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# with torch.no_grad():\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# training()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m loss_history = [model.fit(train_ds,\n\u001b[0m\u001b[1;32m      6\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNB_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 778\u001b[0;31m         raise ModuleAttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[1;32m    779\u001b[0m             type(self).__name__, name))\n\u001b[1;32m    780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleAttributeError\u001b[0m: 'UNetModel' object has no attribute 'fit'"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# shape incompatible\n",
    "# with torch.no_grad():\n",
    "# training()\n",
    "loss_history = [model.fit(train_ds,\n",
    "                        epochs=config.NB_EPOCHS, \n",
    "                        validation_data=val_ds,\n",
    "                        steps_per_epoch=config.MAX_TRAIN_STEPS,\n",
    "                        # validation_steps=config.VALID_IMG_COUNT,\n",
    "                        batch_size=config.BATCH_SIZE,\n",
    "                        callbacks=callbacks_list\n",
    "                        # workers=1,\n",
    "                        # use_multiprocessing=True # the generator is not very thread safe\n",
    "                )]\n",
    "print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, data_loader, loss_module, num_epochs=config.NB_EPOCHS):\n",
    "    # Set model to train mode\n",
    "    model.train() \n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        for data_inputs, data_labels in data_loader:\n",
    "            \n",
    "            ## Step 1: Move input data to device (only strictly necessary if we use GPU)\n",
    "            data_inputs = data_inputs.to(device)\n",
    "            data_labels = data_labels.to(device)\n",
    "            \n",
    "            ## Step 2: Run the model on the input data\n",
    "            preds = model(data_inputs)\n",
    "            preds = preds.squeeze(dim=1) # Output is [Batch size, 1], but we want [Batch size]\n",
    "            \n",
    "            ## Step 3: Calculate the loss\n",
    "            loss = loss_module(preds, data_labels.float())\n",
    "            \n",
    "            ## Step 4: Perform backpropagation\n",
    "            # Before calculating the gradients, we need to ensure that they are all zero. \n",
    "            # The gradients would not be overwritten, but actually added to the existing ones.\n",
    "            optimizer.zero_grad() \n",
    "            # Perform backpropagation\n",
    "            loss.backward()\n",
    "            \n",
    "            ## Step 5: Update the parameters\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model, optimizer, train_data_loader, loss_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# pip install tensorflow-gpu\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "try:\n",
    "  # Specify an invalid GPU device\n",
    "  with tf.device('/device:GPU:2'):\n",
    "    \n",
    "except RuntimeError as e:\n",
    "  print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"data_preparation\", data_preparation()),\n",
    "    (\"model\", define_model()),\n",
    "    (\"training\", training()),\n",
    "    (\"evaluation\", evaluation()),\n",
    "    # (\"prediction\", prediction()),\n",
    "    # (\"data_cleanup\", data_cleanup())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Putting Everything Together (cf. p. 553 & davor)\n",
    "    - Chaining Transformations\n",
    "    - shuffle data etc.\n",
    "- Präsi: Loading Preprocessing Data with TensorFlow"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
