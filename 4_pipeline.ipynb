{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example p. 109 ff. in hands-on ML ...\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "num_pipeline = Pipeline([ \n",
    "    ('imputer', SimpleImputer (strategy=\" median\")), \n",
    "    ('attribs_adder', CombinedAttributesAdder()), \n",
    "    ('std_scaler', StandardScaler()), \n",
    "])\n",
    "housing_num_tr = num_pipeline.fit_transform(housing_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_attribs = list(housing_num)\n",
    "cat_attribs = [\"ocean_proximity\"]\n",
    "full_pipeline = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, num_attribs),\n",
    "    (\"cat\", OneHotEncoder(), cat_attribs),\n",
    "])\n",
    "housing_prepared = full_pipeline.fit_transform(housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example p. 296\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "clf = Pipeline ([\n",
    "    (\"kpca\", KernelPCA(n_components=2)),\n",
    "    (\"log_reg\", LogisticRegression())\n",
    "])\n",
    "param_grid = [{\n",
    "    \"kpca_ _gamma\": np.linspace (0.03, 0.05, 10),\n",
    "    \"kpca__kernel\": [\"rbf\", \"sigmoid\"]\n",
    "}]\n",
    "\n",
    "grid_search = GridSearchCV (clf, param_grid, cv=3) \n",
    "grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example p. 327\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"means\", KMeans(n_clusters=50)),\n",
    "    (\"log_reg\", LogisticRegression()),\n",
    "])\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Putting Everything Together (cf. p. 553 & davor)\n",
    "    - Chaining Transformations\n",
    "    - shuffle data etc.\n",
    "- Pr√§si: Loading Preprocessing Data with TensorFlow\n",
    "\n",
    "##### cool methods\n",
    "- concatenate() \n",
    "- zip()\n",
    "- window()\n",
    "- reduce()\n",
    "- shard()\n",
    "- flat_map()\n",
    "- padded_batch()\n",
    "- from_generator()\n",
    "- from_tensors()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
